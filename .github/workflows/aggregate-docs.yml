name: SpecterOps Complete Documentation Aggregator

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:
  push:
    branches: [main]
    paths: ['.github/workflows/*.yml']

env:
  GIT_AUTHOR_NAME: SpecterOps Documentation Bot
  GIT_AUTHOR_EMAIL: docs-bot@specterops.io

jobs:
  aggregate-complete-documentation:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
      
      - name: Setup Python Environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install Dependencies
        run: |
          pip install requests pyyaml beautifulsoup4 lxml markdownify
          
      - name: Setup Directory Structure
        run: |
          rm -rf docs/tools/*
          mkdir -p docs/tools/{core-platforms,c2-frameworks,data-analysis,utilities,browse}
      
      - name: Create Tagging System
        run: |
          cat > tagging_system.py << 'EOF'
          import json
          import re
          from pathlib import Path
          from collections import defaultdict
          import yaml
          
          class SpecterOpsTagging:
              def __init__(self):
                  self.manual_tags = {
                      "bloodhound_community_edition": {
                          "platforms": ["windows", "linux", "macos"],
                          "techniques": ["reconnaissance", "lateral-movement"],
                          "environments": ["active-directory", "azure"],
                          "categories": ["data-analysis", "enumeration"],
                          "roles": ["red-team", "blue-team"],
                          "difficulty": ["intermediate"]
                      },
                      "mythic_c2": {
                          "platforms": ["windows", "macos", "linux"],
                          "techniques": ["command-control", "execution", "persistence"],
                          "environments": ["active-directory", "azure"],
                          "categories": ["c2-framework", "post-exploitation"],
                          "roles": ["red-team", "consultant"],
                          "difficulty": ["intermediate", "advanced"]
                      },
                      "ghostwriter": {
                          "platforms": ["cross-platform"],
                          "categories": ["reporting", "infrastructure"],
                          "roles": ["red-team", "consultant", "blue-team"],
                          "difficulty": ["beginner", "intermediate"],
                          "integrations": ["mythic", "cobalt-strike"]
                      },
                      "nemesis": {
                          "platforms": ["cross-platform"],
                          "techniques": ["collection", "reconnaissance"],
                          "environments": ["active-directory", "azure"],
                          "categories": ["data-analysis", "post-exploitation"],
                          "roles": ["red-team", "researcher"],
                          "difficulty": ["advanced"]
                      },
                      "sharpsccm": {
                          "platforms": ["windows"],
                          "techniques": ["lateral-movement", "privilege-escalation"],
                          "environments": ["active-directory"],
                          "categories": ["post-exploitation", "enumeration"],
                          "roles": ["red-team"],
                          "difficulty": ["intermediate"]
                      },
                      "sharphound": {
                          "platforms": ["windows"],
                          "techniques": ["reconnaissance"],
                          "environments": ["active-directory"],
                          "categories": ["enumeration", "data-analysis"],
                          "roles": ["red-team", "blue-team"],
                          "difficulty": ["beginner"],
                          "integrations": ["bloodhound"]
                      }
                  }
              
              def get_tool_tags(self, tool_name):
                  safe_name = re.sub(r'[^\w\-]', '_', tool_name.lower()).replace(' ', '_')
                  return self.manual_tags.get(safe_name, {})
              
              def add_tags_to_frontmatter(self, frontmatter, tags):
                  if tags:
                      frontmatter["tags"] = []
                      frontmatter["tag_categories"] = {}
                      
                      for category, tag_list in tags.items():
                          if tag_list:
                              frontmatter["tag_categories"][category] = tag_list
                              frontmatter["tags"].extend(tag_list)
                  
                  return frontmatter
              
              def create_tag_display(self, tags):
                  if not tags:
                      return ""
                  
                  display = ""
                  for category, tag_list in tags.items():
                      if tag_list:
                          category_name = category.replace("-", " ").title()
                          tag_names = [tag.replace("-", " ").title() for tag in tag_list]
                          display += f"**{category_name}**: {', '.join(tag_names)}\n\n"
                  
                  return display + "\n"
          EOF
      
      - name: Create Complete Documentation Processor
        run: |
          cat > complete_docs_processor.py << 'EOF'
          import json
          import subprocess
          import requests
          from pathlib import Path
          from bs4 import BeautifulSoup
          import re
          import yaml
          import os
          from urllib.parse import urljoin, urlparse
          import time
          
          # Import tagging system
          exec(open('tagging_system.py').read())
          
          class CompleteDocsProcessor:
              def __init__(self):
                  self.tools_config = {
                      "core-platforms": [
                          {
                              "name": "BloodHound Community Edition",
                              "repo": "SpecterOps/BloodHound",
                              "source_type": "mintlify_site",
                              "docs_url": "https://bloodhound.specterops.io",
                              "description": "Attack path analysis for Active Directory and Azure environments",
                              "subdomain": "bloodhound"
                          },
                          {
                              "name": "Ghostwriter",
                              "repo": "GhostManager/Ghostwriter",
                              "source_type": "gitbook",
                              "docs_url": "https://specterops.gitbook.io/ghostwriter",
                              "description": "Project management and reporting engine for red teams",
                              "subdomain": "ghostwriter"
                          },
                          {
                              "name": "Nemesis",
                              "repo": "SpecterOps/Nemesis",
                              "source_type": "github_wiki",
                              "docs_url": "https://github.com/SpecterOps/Nemesis/wiki",
                              "description": "Offensive data enrichment pipeline",
                              "subdomain": "nemesis"
                          }
                      ],
                      "c2-frameworks": [
                          {
                              "name": "Mythic C2",
                              "repo": "its-a-feature/Mythic",
                              "source_type": "external_docs_site",
                              "docs_url": "https://docs.mythic-c2.net",
                              "description": "Multi-platform, collaborative red teaming C2 framework",
                              "subdomain": "mythic"
                          }
                      ],
                      "utilities": [
                          {
                              "name": "SharpSCCM",
                              "repo": "Mayyhem/SharpSCCM", 
                              "source_type": "github_wiki",
                              "docs_url": "https://github.com/Mayyhem/SharpSCCM/wiki",
                              "description": "Post-exploitation tool for Microsoft SCCM"
                          },
                          {
                              "name": "SharpHound",
                              "repo": "BloodHoundAD/SharpHound",
                              "source_type": "github_readme",
                              "description": "Official data collector for BloodHound",
                              "subdomain": "sharphound"
                          }
                      ]
                  }
              
              def process_all_tools(self):
                  all_tools = {}
                  
                  for category, tools in self.tools_config.items():
                      print(f"Processing category: {category}")
                      
                      for tool_config in tools:
                          print(f"  Processing {tool_config['name']}...")
                          
                          safe_name = re.sub(r'[^\w\-]', '_', tool_config['name'].lower()).replace(' ', '_')
                          tool_dir = Path(f"docs/tools/{category}/{safe_name}")
                          tool_dir.mkdir(parents=True, exist_ok=True)
                          
                          # Process based on source type
                          source_type = tool_config.get('source_type', 'github_readme')
                          
                          if source_type == "github_wiki":
                              pages = self.process_github_wiki(tool_config, tool_dir)
                          elif source_type == "gitbook":
                              pages = self.process_gitbook(tool_config, tool_dir)
                          elif source_type == "mintlify_site":
                              pages = self.process_mintlify_site(tool_config, tool_dir)
                          elif source_type == "external_docs_site":
                              pages = self.process_external_docs_site(tool_config, tool_dir)
                          else:
                              pages = self.process_github_readme(tool_config, tool_dir)
                          
                          if pages:
                              self.apply_tags_to_pages(tool_config, tool_dir, pages)
                              all_tools[f"{category}/{safe_name}"] = {
                                  "name": tool_config['name'],
                                  "pages": pages
                              }
                              print(f"    Created {len(pages)} pages")
                  
                  return all_tools
              
              def process_github_wiki(self, tool_config, tool_dir):
                  repo = tool_config['repo']
                  
                  try:
                      # Check if wiki exists
                      wiki_url = f"https://github.com/{repo}/wiki"
                      response = requests.get(wiki_url, timeout=30)
                      if response.status_code == 404:
                          print(f"    No wiki found, falling back to README")
                          return self.process_github_readme(tool_config, tool_dir)
                      
                      # Clone wiki repository
                      wiki_repo_url = f"https://github.com/{repo}.wiki.git"
                      clone_dir = f"temp_wiki_{repo.split('/')[-1]}"
                      
                      subprocess.run([
                          'git', 'clone', wiki_repo_url, clone_dir
                      ], check=True, capture_output=True)
                      
                      pages = []
                      wiki_path = Path(clone_dir)
                      
                      # Process all markdown files
                      for md_file in wiki_path.glob("*.md"):
                          if md_file.name == "Home.md":
                              page_name = "index"
                          else:
                              page_name = md_file.stem.lower().replace(' ', '-')
                          
                          with open(md_file, 'r', encoding='utf-8') as f:
                              content = f.read()
                          
                          # Convert wiki links
                          content = self.convert_wiki_links(content, repo)
                          
                          # Create page
                          title = md_file.stem.replace('-', ' ').replace('_', ' ')
                          if title.lower() == "home":
                              title = tool_config['name']
                          
                          frontmatter = {
                              "title": f'"{title}"',
                              "description": f'"{title} documentation"'
                          }
                          
                          output_file = tool_dir / f"{page_name}.md"
                          yaml_fm = yaml.dump(frontmatter, default_flow_style=False)
                          full_content = f"---\n{yaml_fm}---\n\n{content}"
                          
                          with open(output_file, 'w', encoding='utf-8') as f:
                              f.write(full_content)
                          
                          pages.append(page_name)
                      
                      subprocess.run(['rm', '-rf', clone_dir], check=False)
                      return pages
                      
                  except Exception as e:
                      print(f"    Error processing wiki: {e}")
                      return self.process_github_readme(tool_config, tool_dir)
              
              def process_gitbook(self, tool_config, tool_dir):
                  # Simplified GitBook processing
                  try:
                      base_url = tool_config['docs_url']
                      response = requests.get(base_url, timeout=30)
                      response.raise_for_status()
                      
                      soup = BeautifulSoup(response.content, 'html.parser')
                      
                      # Remove unwanted elements
                      for element in soup.find_all(['nav', 'header', 'footer', 'script', 'style']):
                          element.decompose()
                      
                      # Get main content
                      content_area = soup.find('main') or soup.find('article') or soup.find('div', class_='content')
                      
                      if content_area:
                          content = content_area.get_text(separator='\n', strip=True)
                      else:
                          content = soup.get_text(separator='\n', strip=True)
                      
                      # Create main page
                      frontmatter = {
                          "title": f'"{tool_config["name"]}"',
                          "description": f'"{tool_config["description"]}"'
                      }
                      
                      output_file = tool_dir / "index.md"
                      yaml_fm = yaml.dump(frontmatter, default_flow_style=False)
                      full_content = f"---\n{yaml_fm}---\n\n# {tool_config['name']}\n\n{content}"
                      
                      with open(output_file, 'w', encoding='utf-8') as f:
                          f.write(full_content)
                      
                      return ["index"]
                      
                  except Exception as e:
                      print(f"    Error processing GitBook: {e}")
                      return self.process_github_readme(tool_config, tool_dir)
              
              def process_mintlify_site(self, tool_config, tool_dir):
                  # Simplified Mintlify site processing
                  try:
                      base_url = tool_config['docs_url']
                      response = requests.get(base_url, timeout=30)
                      response.raise_for_status()
                      
                      soup = BeautifulSoup(response.content, 'html.parser')
                      
                      # Remove unwanted elements
                      for element in soup.find_all(['nav', 'header', 'footer', 'script', 'style', 'aside']):
                          element.decompose()
                      
                      # Get main content
                      content_area = soup.find('main') or soup.find('article') or soup.find('div', class_='content')
                      
                      if content_area:
                          content = content_area.get_text(separator='\n', strip=True)
                      else:
                          content = soup.get_text(separator='\n', strip=True)
                      
                      # Create main page
                      frontmatter = {
                          "title": f'"{tool_config["name"]}"',
                          "description": f'"{tool_config["description"]}"'
                      }
                      
                      output_file = tool_dir / "index.md"
                      yaml_fm = yaml.dump(frontmatter, default_flow_style=False)
                      full_content = f"---\n{yaml_fm}---\n\n# {tool_config['name']}\n\n{content}"
                      
                      with open(output_file, 'w', encoding='utf-8') as f:
                          f.write(full_content)
                      
                      return ["index"]
                      
                  except Exception as e:
                      print(f"    Error processing Mintlify site: {e}")
                      return self.process_github_readme(tool_config, tool_dir)
              
              def process_external_docs_site(self, tool_config, tool_dir):
                  # Simplified external docs processing
                  try:
                      base_url = tool_config['docs_url']
                      response = requests.get(base_url, timeout=30)
                      response.raise_for_status()
                      
                      soup = BeautifulSoup(response.content, 'html.parser')
                      
                      # Remove unwanted elements
                      for element in soup.find_all(['nav', 'header', 'footer', 'script', 'style', 'aside']):
                          element.decompose()
                      
                      # Get main content
                      content_area = soup.find('main') or soup.find('article') or soup.find('div', class_='content')
                      
                      if content_area:
                          content = content_area.get_text(separator='\n', strip=True)
                      else:
                          content = soup.get_text(separator='\n', strip=True)
                      
                      # Create main page
                      frontmatter = {
                          "title": f'"{tool_config["name"]}"',
                          "description": f'"{tool_config["description"]}"'
                      }
                      
                      output_file = tool_dir / "index.md"
                      yaml_fm = yaml.dump(frontmatter, default_flow_style=False)
                      full_content = f"---\n{yaml_fm}---\n\n# {tool_config['name']}\n\n{content}"
                      
                      with open(output_file, 'w', encoding='utf-8') as f:
                          f.write(full_content)
                      
                      return ["index"]
                      
                  except Exception as e:
                      print(f"    Error processing external docs: {e}")
                      return self.process_github_readme(tool_config, tool_dir)
              
              def process_github_readme(self, tool_config, tool_dir):
                  repo = tool_config['repo']
                  
                  try:
                      clone_dir = f"temp_{repo.split('/')[-1]}"
                      subprocess.run([
                          'git', 'clone', '--depth', '1',
                          f'https://github.com/{repo}.git', clone_dir
                      ], check=True, capture_output=True)
                      
                      readme_path = Path(clone_dir) / "README.md"
                      if readme_path.exists():
                          with open(readme_path, 'r', encoding='utf-8') as f:
                              content = f.read()
                          
                          # Fix relative links
                          repo_base = f"https://github.com/{repo}/blob/main"
                          content = re.sub(
                              r'!\[([^\]]*)\]\((?!http)([^)]+)\)',
                              rf'![\1]({repo_base}/\2)',
                              content
                          )
                          
                          frontmatter = {
                              "title": f'"{tool_config["name"]}"',
                              "description": f'"{tool_config["description"]}"'
                          }
                          
                          output_file = tool_dir / "index.md"
                          yaml_fm = yaml.dump(frontmatter, default_flow_style=False)
                          full_content = f"---\n{yaml_fm}---\n\n# {tool_config['name']}\n\n{content}"
                          
                          with open(output_file, 'w', encoding='utf-8') as f:
                              f.write(full_content)
                          
                          subprocess.run(['rm', '-rf', clone_dir], check=False)
                          return ["index"]
                      
                  except Exception as e:
                      print(f"    Error processing README: {e}")
                  
                  return []
              
              def convert_wiki_links(self, content, repo):
                  # Convert [[Page Name]] to [Page Name](./page-name)
                  def replace_wiki_link(match):
                      page_name = match.group(1)
                      safe_name = page_name.lower().replace(' ', '-').replace('_', '-')
                      return f"[{page_name}](./{safe_name})"
                  
                  content = re.sub(r'\[\[([^\]]+)\]\]', replace_wiki_link, content)
                  
                  # Fix image links
                  repo_base = f"https://github.com/{repo}/wiki"
                  content = re.sub(
                      r'!\[([^\]]*)\]\((?!http)([^)]+)\)',
                      rf'![\1]({repo_base}/\2)',
                      content
                  )
                  
                  return content
              
              def apply_tags_to_pages(self, tool_config, tool_dir, pages):
                  try:
                      tagging = SpecterOpsTagging()
                      tool_name = tool_config['name']
                      tags = tagging.get_tool_tags(tool_name)
                      
                      # Apply tags to each page
                      for page_name in pages:
                          page_file = tool_dir / f"{page_name}.md"
                          if page_file.exists():
                              with open(page_file, 'r', encoding='utf-8') as f:
                                  content = f.read()
                              
                              # Parse frontmatter
                              if content.startswith('---'):
                                  parts = content.split('---', 2)
                                  if len(parts) >= 3:
                                      frontmatter = yaml.safe_load(parts[1]) or {}
                                      body = parts[2]
                                  else:
                                      frontmatter = {}
                                      body = content
                              else:
                                  frontmatter = {}
                                  body = content
                              
                              # Add tags
                              frontmatter = tagging.add_tags_to_frontmatter(frontmatter, tags)
                              
                              # Add tag display to main page
                              if page_name == "index":
                                  tag_display = tagging.create_tag_display(tags)
                                  if tag_display and "**Platforms**:" not in body:
                                      body = tag_display + body
                              
                              # Write back
                              yaml_fm = yaml.dump(frontmatter, default_flow_style=False)
                              updated_content = f"---\n{yaml_fm}---\n{body}"
                              
                              with open(page_file, 'w', encoding='utf-8') as f:
                                  f.write(updated_content)
                                  
                  except Exception as e:
                      print(f"    Could not apply tags: {e}")
          
          def main():
              processor = CompleteDocsProcessor()
              result = processor.process_all_tools()
              
              print(f"Processing complete!")
              for tool_path, tool_data in result.items():
                  print(f"  {tool_data['name']}: {len(tool_data['pages'])} pages")
          
          if __name__ == "__main__":
              main()
          EOF
      
      - name: Process Complete Documentation
        run: |
          cd scripts
          python complete_docs_processor.py
      
      - name: Create Browse Pages
        run: |
          python -c "
          exec(open('tagging_system.py').read())
          from pathlib import Path
          import json
          
          # Create simple browse structure
          browse_dir = Path('docs/tools/browse')
          browse_dir.mkdir(exist_ok=True)
          
          with open(browse_dir / 'index.md', 'w') as f:
              f.write('''---
          title: \"Browse Tools by Tags\"
          description: \"Find SpecterOps tools by category\"
          ---
          
          # Browse Tools by Tags
          
          <CardGroup cols={2}>
            <Card title=\"By Platform\" href=\"./platforms\">
              Windows, macOS, Linux, Cross-platform
            </Card>
            <Card title=\"By Technique\" href=\"./techniques\">
              Reconnaissance, Lateral Movement, etc.
            </Card>
            <Card title=\"By Environment\" href=\"./environments\">
              Active Directory, Azure, AWS
            </Card>
            <Card title=\"By Role\" href=\"./roles\">
              Red Team, Blue Team, Research
            </Card>
          </CardGroup>
          ''')
          
          # Create basic category pages
          categories = ['platforms', 'techniques', 'environments', 'roles']
          for category in categories:
              with open(browse_dir / f'{category}.md', 'w') as f:
                  title = category.replace('-', ' ').title()
                  f.write(f'''---
          title: \"Browse by {title}\"
          description: \"Find tools by {title.lower()}\"
          ---
          
          # Browse by {title}
          
          Browse tools organized by {title.lower()}.
          ''')
          "
      
      - name: Create Updated Mintlify Configuration
        run: |
          cat > mint.json << 'EOF'
          {
            "$schema": "https://mintlify.com/schema.json",
            "name": "SpecterOps Documentation Hub",
            "logo": {
              "dark": "/logo/specterops-dark.svg",
              "light": "/logo/specterops-light.svg"
            },
            "favicon": "/favicon.ico",
            "colors": {
              "primary": "#FF4B4B",
              "light": "#FF6B6B",
              "dark": "#E53E3E"
            },
            "topbarCtaButton": {
              "name": "SpecterOps",
              "url": "https://specterops.io"
            },
            "navigation": [
              {
                "group": "Getting Started",
                "pages": [
                  "docs/tools/browse/index"
                ]
              },
              {
                "group": "Browse by Tags",
                "pages": [
                  "docs/tools/browse/platforms",
                  "docs/tools/browse/techniques", 
                  "docs/tools/browse/environments",
                  "docs/tools/browse/roles"
                ]
              },
              {
                "group": "Core Platforms",
                "pages": [
                  "docs/tools/core-platforms/bloodhound_community_edition/index",
                  "docs/tools/core-platforms/ghostwriter/index",
                  "docs/tools/core-platforms/nemesis/index"
                ]
              },
              {
                "group": "C2 Frameworks",
                "pages": [
                  "docs/tools/c2-frameworks/mythic_c2/index"
                ]
              },
              {
                "group": "Utilities",
                "pages": [
                  "docs/tools/utilities/sharpsccm/index",
                  "docs/tools/utilities/sharphound/index"
                ]
              }
            ],
            "footerSocials": {
              "github": "https://github.com/SpecterOps",
              "x": "https://x.com/specterops"
            },
            "search": {
              "prompt": "Search tools, techniques, platforms..."
            }
          }
          EOF
      
      - name: Commit and Push Changes
        run: |
          git config --local user.email "${{ env.GIT_AUTHOR_EMAIL }}"
          git config --local user.name "${{ env.GIT_AUTHOR_NAME }}"
          
          git add docs/ mint.json
          
          if ! git diff --staged --quiet; then
            TOOL_COUNT=$(find docs/tools -name "*.md" -not -path "docs/tools/browse/*" | wc -l)
            
            git commit -m "ðŸ”„ Update SpecterOps complete documentation

            Features:
            - GitHub Wiki: Full wiki content and navigation
            - GitBook: Complete GitBook sites converted
            - Mintlify Sites: Existing documentation sites
            - External Docs: Full documentation sites like docs.mythic-c2.net
            - Smart tagging system with browse functionality
            
            Generated: ${TOOL_COUNT} documentation pages
            Updated: $(date '+%Y-%m-%d %H:%M UTC')"
            
            git push
            echo "âœ… Complete documentation updated successfully"
          else
            echo "No changes to commit"
          fi