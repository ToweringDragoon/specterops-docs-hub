#!/usr/bin/env node
import yargs from 'yargs';
import { hideBin } from 'yargs/helpers';
import { FINAL_SUCCESS_MESSAGE } from './constants.js';
import { scrapePageGroup } from './scrapingPipeline/group.js';
import { htmlToHast } from './scrapingPipeline/root.js';
import { scrapeAllSiteTabs } from './scrapingPipeline/tabs.js';
import { detectFramework, framework } from './utils/detectFramework.js';
import { write } from './utils/file.js';
import { log } from './utils/log.js';
import { fetchPageHtml } from './utils/network.js';
import { checkUrl } from './utils/url.js';
await yargs(hideBin(process.argv))
    .command('page <url>', 'Scrapes the docs page for the URL provided', (yargs) => yargs.positional('url', { type: 'string', demandOption: true }).check(checkUrl), async ({ url }) => await page(url))
    .command('section <url>', 'Scrapes the entire docs site based on the URL provided', (yargs) => yargs.positional('url', { type: 'string', demandOption: true }).check(checkUrl), async ({ url }) => await site(url))
    .strictCommands()
    .demandCommand(1, 'Unknown command. See above for the list of supported commands.')
    .alias('h', 'help')
    .alias('v', 'version')
    .parse();
async function page(url) {
    const urlObj = new URL(url);
    const html = await fetchPageHtml(urlObj);
    log('Successfully retrieved initial HTML from src: ' + urlObj.toString());
    const hast = htmlToHast(html);
    detectFramework(hast);
    const needsBrowser = framework.vendor === 'gitbook';
    const results = await scrapePageGroup([urlObj], needsBrowser);
    const result = results[0] || {
        success: false,
        message: `An unknown error occurred when scraping ${url}`,
    };
    if (result.success) {
        log(`Successfully scraped ${url} ${result.data ? `into ${result.data[1]}` : ''}`);
    }
    else {
        log(result.message);
    }
}
async function site(url) {
    const urlObj = new URL(url);
    const html = await fetchPageHtml(urlObj);
    log('Successfully retrieved initial HTML from src: ' + urlObj.toString());
    const result = await scrapeAllSiteTabs(html, urlObj);
    if (result.success) {
        write('mint.json', JSON.stringify(result.data, undefined, 2));
        log(FINAL_SUCCESS_MESSAGE);
    }
    else {
        log(result.message);
    }
}
//# sourceMappingURL=cli.js.map